# EEG-Graph-Embedding-with-Small-World-Propensity-Guided-Autoencoders
Abstractâ€” The early identification of developmental delays in toddlers, particularly those related to speech and language, is essential for effective interventions and treatments. Medical practitioners often rely on questionnaires and play-based assessments in standard language scales to identify developmental delays. Besides being cumbersome and time-consuming, these approaches are inconsistent and necessitate subject compliance. Graph convolution networks are effective at modeling graph-structured data such as EEG signals and could facilitate the automation of such assessments. However, the inherent noise present in EEG signals makes the construction of sufficiently representative input graphs difficult. In this study, the representational capacity of a novel spatial-temporal graph autoencoder model is enhanced by leveraging small-world properties to identify thresholds and frequency bands that offer a reasonable balance between preserving essential features and reducing noise. In the proposed architecture, encoder and decoder modules both contain long short-term memory layers to model the temporal properties at each node and graph sampling and aggregation convolution blocks to model internodal relationships. A multilayer perceptron is used to regress receptive and expressive language scale scores from generated embeddings that have been infused with age, gender, and handedness properties. The proposed model is trained using a regression loss as well as a reconstruction loss with structure and connectivity terms to ensure that generated embeddings encapsulate both the temporal properties at each node and the relationships between them. Experimental results show that the proposed approach is capable of reliably predicting receptive and expressive language scores, achieving a mean average error consistently under three.
